# ğŸ‰ EmoStream: Concurrent Emoji Broadcast over Event-Driven Architecture

## ğŸ“ Project Overview

Emojis ğŸ˜„ reflect the dynamic sentiments of fans in real-time. When Virat is batting ğŸ, everyoneâ€™s hoping for boundaries with every ball; when heâ€™s on the field, theyâ€™re cheering for wickets ğŸ¯. Capturing these user-generated signals as they flow in, distilling them into an emoji swarm ğŸ that mirrors the crowdâ€™s mood, and displaying these shifting emotions live is a major challengeâ€”especially with billions of emoji reactions anticipated over the tournament ğŸ“Š.

## ğŸ¯ Goal

The goal of this project was to design and implement a **scalable system** ğŸ§± that enhances the viewer experience on platforms like **Hotstar** ğŸ“º by capturing and processing **billions of user-generated emojis** ğŸ’¬ in real-time during live sporting events. This was achieved by creating a **horizontally scalable architecture** ğŸ› ï¸ using **Kafka** ğŸ“¨ for data streaming and **Spark** âš¡ for real-time data processing. The system ensures **high concurrency** and **low latency**, delivering seamless user interactions ğŸš€.

## ğŸ—ï¸ Architecture

### ğŸ”§ Key Components

1. **API Endpoint and Data Collection** ğŸ“¥  
   - A Flask-based **API endpoint** was created to receive **POST** requests from users, containing the emoji data (User ID ğŸ‘¤, Emoji type ğŸ˜Š, Timestamp â±ï¸).  
   - Each emoji data entry is **asynchronously** written to a Kafka producer âš™ï¸.
   
2. **Kafka Producer and Data Streaming** ğŸ”„  
   - The emoji data is pushed to **Kafka** ğŸ“¦ as a message queue, with a **flush interval** of 500 milliseconds â³ to ensure real-time data transmission to the Kafka broker.

3. **Real-Time Data Processing with Spark** ğŸ”¥  
   - A **Spark Streaming** job consumes the emoji data from Kafka in **micro-batches** ğŸ“Š.  
   - The micro-batches are processed in intervals of 2 seconds âŒ›, with an aggregation algorithm that reduces 1000 or fewer emojis of the same type to a single representative emoji ğŸ­.

4. **Pub-Sub Architecture for Scalability** ğŸ“£  
   - A **Publisher-Subscriber** model is implemented to handle **high concurrency** âš¡.  
   - Multiple **Kafka clusters** are established, each with its own **publisher** ğŸ“¤ and multiple **subscribers** ğŸ“¥.  
   - The main publisher receives aggregated data from Spark and forwards it to the cluster publishers.  
   - Subscribers handle the distribution of messages to clients, ensuring **real-time updates** ğŸ§  to users.

5. **Client Registration and Seamless Connection Management** ğŸ”—  
   - Clients can register with the subscribers to receive real-time emoji updates ğŸ’¬.  
   - The system supports **dynamic client registration** and **removal** ğŸ”„, ensuring no interruptions in the live data flow ğŸ›œ.


- **API Endpoint**: A Flask API that accepts emoji data from users and sends it asynchronously to the Kafka producer ğŸ§‘â€ğŸ’».
- **Kafka Producer**: The producer writes emoji data to Kafka with a flush interval of 0.5 seconds â²ï¸.
- **Spark Streaming Job**: A job that processes the emoji data in 2-second intervals, applying the aggregation logic to reduce emojis ğŸ”.
- **Publisher-Subscriber Architecture**: A robust architecture that scales to handle large numbers of clients with multiple clusters, each with a cluster publisher and several subscribers ğŸ”„.
- **Real-Time Data Delivery**: The aggregated emoji data is delivered back to clients in real time, with seamless handling of client connections ğŸ“¡.

## ğŸ§ª Testing

- **Unit Testing**: Tests were created for the API endpoints to ensure they could handle thousands of emoji requests per second ğŸ”.
- **Load Testing**: The system was stress-tested ğŸ§± to ensure it could handle high concurrency with thousands of concurrent clients sending emoji data ğŸ”„.
- **Scalability Testing**: The Pub-Sub model was tested to ensure real-time data delivery to users, even under high load ğŸš¦.

## ğŸ¥ Demo

The system was demonstrated with multiple clients sending emoji data to the API endpoint ğŸ“¤. Kafka producer asynchronously received and wrote emoji data to the Kafka broker ğŸ“¦, and the Kafka consumer processed and aggregated the data using Spark Streaming ğŸ”¥. The aggregated data was then distributed to clients through the Pub-Sub architecture ğŸ“£, ensuring that all clients received **real-time emoji updates** â±ï¸âœ¨.
